{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# ASUM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from collections import Counter\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from reviews.config import processed_data_dir, asum_input_dir, asum_output_dir\n",
    "from reviews.models import asum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Generate Input Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# load tokens\n",
    "reviews_df = pd.read_json(processed_data_dir / \"preprocessed_reviews.json.gz\")\n",
    "\n",
    "# load vocabulary\n",
    "vocabulary = np.load(asum_input_dir / \"vocabulary.npy\", allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "with open(asum_input_dir / \"WordList.txt\", \"w\") as f:\n",
    "    for word in vocabulary:\n",
    "        f.write(f\"{word}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sentence_list = asum_input_dir / \"BagOfSentences.txt\"\n",
    "\n",
    "if os.path.exists(sentence_list):\n",
    "    os.remove(sentence_list)\n",
    "\n",
    "with open(sentence_list, \"a\") as f:\n",
    "    for doc in reviews_df[\"tokens\"]:\n",
    "        f.write(f\"{len(doc)}\\n\")\n",
    "        for tokens in doc:\n",
    "            indexes = \" \".join([str(vocabulary[t]) for t in tokens])\n",
    "            f.write(f\"{indexes}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "alpha = 0.1\n",
    "beta = [0.001, 0.1, 0]\n",
    "gamma = [1, 1]\n",
    "n_topics = 5\n",
    "iterations = 1000\n",
    "\n",
    "asum(\n",
    "    str(alpha),\n",
    "    \"/\".join([str(x) for x in beta]),\n",
    "    \"/\".join([str(x) for x in gamma]),\n",
    "    str(n_topics),\n",
    "    iterations=str(iterations),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "filename_prefix = f\"STO2-T{n_topics}-S2(2)-A{alpha}-B{','.join([f'{float(x)}' for x in beta])}-G{','.join([f'{float(x):.1f}' for x in gamma])}-I{iterations}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(asum_output_dir / f\"{filename_prefix}-ProbWords.csv\")\n",
    "\n",
    "\n",
    "def map_topic_sentiment(column_name):\n",
    "    if \"Unnamed\" in column_name:\n",
    "        return None\n",
    "\n",
    "    values = column_name.split(\"-\")\n",
    "    return {\n",
    "        \"sentiment\": int(values[0][1]),\n",
    "        \"topic\": int(values[1][1]),\n",
    "        \"colname\": column_name,\n",
    "    }\n",
    "\n",
    "\n",
    "columns = df.columns.map(map_topic_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def get_word_weight(text):\n",
    "    match = re.match(\"(\\w+)\\s+\\((.*?)\\)\", text)\n",
    "    word, weight = match.groups()\n",
    "    return word, float(weight)\n",
    "\n",
    "\n",
    "n_topics = 5\n",
    "n_top_words = 10\n",
    "\n",
    "fig, axes = plt.subplots(2, n_topics, figsize=(15, 6), sharex=\"all\")\n",
    "axes = axes.flatten()\n",
    "\n",
    "for idx, item in enumerate(columns):\n",
    "    if item is None:\n",
    "        continue\n",
    "\n",
    "    ax = axes[idx]\n",
    "    words = df[item[\"colname\"]][:n_top_words]\n",
    "    weights = list(map(list, zip(*words.map(get_word_weight))))\n",
    "\n",
    "    weights = pd.DataFrame({\"names\": weights[0], \"weights\": weights[1]})\n",
    "    weights.sort_values(\"weights\", inplace=True)\n",
    "\n",
    "    ax.barh(weights[\"names\"], weights[\"weights\"], height=0.5)\n",
    "    ax.set_title(item[\"colname\"])\n",
    "\n",
    "    if idx > n_topics - 1:\n",
    "        ax.set_xlabel(f\"Topic {item['topic'] + 1}\")\n",
    "\n",
    "    if idx == 0 or idx == n_topics:\n",
    "        ax.set_ylabel(\"Positive\" if item[\"sentiment\"] == 0 else \"Negative\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df1 = pd.DataFrame(list(df[\"S0-T0\"].apply(get_word_weight)), columns=[\"word\", \"positive\"])\n",
    "df2 = pd.DataFrame(list(df[\"S1-T0\"].apply(get_word_weight)), columns=[\"word\", \"negative\"])\n",
    "\n",
    "df_tot = pd.merge(df1, df2, on=\"word\", how=\"left\")\n",
    "df_tot.sort_values(by=\"positive\", ascending=False, inplace=True)\n",
    "df_tot = df_tot[:10]\n",
    "\n",
    "df_tot.set_index(\"word\", inplace=True)\n",
    "df_tot = df_tot.rename_axis(columns=[\"sentiment\"]).stack().rename(\"value\")\n",
    "df_tot = df_tot.reset_index()\n",
    "\n",
    "df_tot.sort_values(by=\"value\", ascending=False, inplace=True)\n",
    "df_tot = df_tot[:20]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.barplot(\n",
    "    y=df_tot[\"word\"],\n",
    "    x=df_tot[\"value\"],\n",
    "    hue=df_tot[\"sentiment\"],\n",
    "    dodge=True,\n",
    "    palette=sns.color_palette(\"terrain\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "pi_df = pd.read_csv(asum_output_dir / f\"{filename_prefix}-Pi.csv\", header=None)\n",
    "\n",
    "doc_sentiment = pi_df.idxmax(axis=1).map(lambda x: \"positive\" if x == 0 else \"negative\")\n",
    "doc_sentiment.loc[pi_df[0] == 0.5] = \"neutral\"\n",
    "\n",
    "reviews_df[\"sentiment\"] = doc_sentiment\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(10, 3))\n",
    "sns.histplot(x=doc_sentiment, ax=axes[0])\n",
    "\n",
    "counts = doc_sentiment.value_counts()\n",
    "counts.plot(\n",
    "    ax=axes[1],\n",
    "    kind=\"pie\",\n",
    "    colors=sns.color_palette(\"pastel\")[0:7],\n",
    "    autopct=\"%.0f%%\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "theta_df = pd.read_csv(asum_output_dir / f\"{filename_prefix}-Theta.csv\")\n",
    "theta_df.drop(columns=[\"Unnamed: 10\"], inplace=True)\n",
    "\n",
    "mask = theta_df >= 0.3\n",
    "mask = mask.apply(lambda x: list(mask.columns[x]), axis=1)\n",
    "\n",
    "reviews_df[\"topics\"] = mask.apply(lambda x: list(map(map_topic_sentiment, x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "reviews_df.to_json(asum_output_dir / \"topics.json\", orient=\"records\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phi_df = pd.read_csv(asum_output_dir / f\"{filename_prefix}-Phi.csv\")\n",
    "phi_df.sort_values(by=\"S1-T1\", ascending=False, inplace=True)\n",
    "phi_df[\"S1-T1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### WordClouds by Topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wc = WordCloud(height=400, width=800)\n",
    "wc.generate_from_frequencies(\n",
    "    dict(zip(phi_df[\"Unnamed: 0\"].values, phi_df[\"S1-T4\"].values))\n",
    ")\n",
    "wc.to_image()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "theta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pi_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "phi_df.sort_values(\"S1-T1\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "count = Counter()\n",
    "\n",
    "for x in reviews_df[\"topics\"].values:\n",
    "    topics = set([\"T\" + str(y[\"topic\"]) for y in x])\n",
    "    count.update(topics)\n",
    "\n",
    "topics_count = pd.DataFrame(count.items(), columns=[\"topic\", \"count\"])\n",
    "topics_count[\"topic\"] = topics_count[\"topic\"].astype(\"category\")\n",
    "\n",
    "order = topics_count.sort_values(by=\"count\", ascending=False).topic\n",
    "fig = plt.figure(figsize=(8, 5))\n",
    "ax = sns.barplot(\n",
    "    y=topics_count[\"topic\"], x=topics_count[\"count\"], order=order, orient=\"h\"\n",
    ")\n",
    "ax.set_title(\"Topics\")\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Filtrare i topic-sentiment classificando il sentiment\n",
    "\n",
    "- T1-S0: 34, T1-S1: 56 ---> S1\n",
    "- T1-S0: 74, T1-S1: 21 ---> S0\n",
    "- T1-S0: 67, T1-S1: 67 ---> S2 (neutral?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pos_count = Counter()\n",
    "neg_count = Counter()\n",
    "\n",
    "\n",
    "for x in reviews_df[\"topics\"].values:\n",
    "    pos_topics = set([\"T\" + str(st[\"topic\"]) for st in x if st[\"sentiment\"] == 0])\n",
    "    neg_topics = set([\"T\" + str(st[\"topic\"]) for st in x if st[\"sentiment\"] == 1])\n",
    "\n",
    "    pos_count.update(pos_topics)\n",
    "    neg_count.update(neg_topics)\n",
    "\n",
    "\n",
    "pos_df = pd.DataFrame(pos_count.items(), columns=[\"topic\", \"pos\"])\n",
    "neg_df = pd.DataFrame(neg_count.items(), columns=[\"topic\", \"neg\"])\n",
    "\n",
    "st_counts = pd.merge(pos_df, neg_df, on=\"topic\")\n",
    "st_counts[\"topic\"] = st_counts[\"topic\"].astype(\"category\")\n",
    "\n",
    "total = st_counts[\"pos\"] + st_counts[\"neg\"]\n",
    "st_counts[\"pos\"] = st_counts[\"pos\"] / total * 100\n",
    "st_counts[\"neg\"] = st_counts[\"neg\"] / total * 100\n",
    "\n",
    "st_counts.set_index(\"topic\", inplace=True)\n",
    "st_counts.sort_index(inplace=True)\n",
    "st_counts = st_counts.iloc[[int(o[1]) for o in order][::-1]]\n",
    "\n",
    "st_counts.plot(kind=\"barh\", stacked=True, color=[\"red\", \"green\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prod_df = pd.read_json(processed_data_dir / \"meta_computer_components.json.gz\")\n",
    "data_df = pd.merge(left=prod_df, right=reviews_df, on=\"asin\")\n",
    "\n",
    "# data_df = data_df.loc[data_df[\"brand\"] == \"Intel\"]\n",
    "data_df = data_df.loc[data_df[\"sentiment\"] == \"positive\"]\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "sns.histplot(x=data_df[\"timestamp\"], hue=data_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prod_df = pd.read_json(processed_data_dir / \"meta_computer_components.json.gz\")\n",
    "data_df = pd.merge(left=prod_df, right=reviews_df, on=\"asin\")\n",
    "\n",
    "data_df = data_df.loc[data_df[\"sentiment\"] == \"negative\"]\n",
    "fig = plt.figure(figsize=(20, 4))\n",
    "sns.histplot(x=data_df[\"timestamp\"], hue=data_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prod_df = pd.read_json(processed_data_dir / \"meta_computer_components.json.gz\")\n",
    "data_df = pd.merge(left=prod_df, right=reviews_df, on=\"asin\")\n",
    "data_df = data_df.loc[data_df[\"brand\"].isin([\"Intel\", \"AMD\", \"Dell\", \"Asus\"])]\n",
    "\n",
    "fig = plt.figure(figsize=(20, 10))\n",
    "sns.countplot(x=data_df[\"brand\"], hue=data_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prod_df = pd.read_json(processed_data_dir / \"meta_computer_components.json.gz\")\n",
    "data_df = pd.merge(left=prod_df, right=reviews_df, on=\"asin\")\n",
    "\n",
    "data_df[\"category\"] = data_df[\"category\"].apply(lambda x: x[4] if len(x) > 4 else \"other\")\n",
    "\n",
    "fig = plt.figure(figsize=(30, 10))\n",
    "plt.xticks(rotation=45)\n",
    "sns.countplot(x=data_df[\"category\"].astype(\"string\"), hue=data_df[\"sentiment\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# topic sentiment nel tempo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "t = pd.crosstab(\n",
    "    data_df[\"overall\"].apply(\n",
    "        lambda x: \"negative\" if x < 3 else (\"neutral\" if x == 3 else \"positive\")\n",
    "    ),\n",
    "    data_df[\"sentiment\"].astype(\"category\"),\n",
    ")\n",
    "t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "cm = t.to_numpy()\n",
    "np.sum(cm.diagonal()) / np.sum(cm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d5612a16ccaf4c3fb4cfcdb0e5985a4869a17ac33fc51daeb1c4e0cb99779cee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}