{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# JST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_status = 1\n",
      "Please specify input data dir!\n",
      "Command line usage:\n",
      "jst -est|-inf [options]\n",
      "-est \t Estimate the DJST model from scratch.\n",
      "-inf \t Perform inference on unseen (new) data using a trained model.\n",
      "\n",
      "-----------------------------------------------------------\n",
      "Command line opitions:\n",
      "\n",
      "-nsentiLabs \t The number of sentiment labels. The default is 3.\n",
      "-ntopics \t The number of topics. The default is 50.\n",
      "-niters \t The number of Gibbs sampling iterations. The default is 1000.\n",
      "-savestep \t The step (counted by the number of Gibbs sampling iterations) at which the model is saved to hard disk. The default is 200.\n",
      "-updateParaStep The step (counted by the number of Gibbs sampling iterations) at which the hyperparameters are updated. The default is 40.\n",
      "-twords \t The number of most likely words to be printed for each topic. The default is 20.\n",
      "-data_dir \t The directory where the input training data is stored.\n",
      "-result_dir \t The directory where the output models and parameters will be stored.\n",
      "-datasetFile \t The input training data file.\n",
      "-sentiFile \t The sentiment lexicon file.\n",
      "-vocab \t\t The vocabulary file.\n",
      "-alpha \t\t The hyperparameter of the per-document sentiment specific topic proportion. The default is avgDocLength*0.05/(numSentiLabs*numTopics).\n",
      "-beta \t\t The hyperparameter of the per-corpus sentiment specific topic-word distribution. The default is 0.01.\n",
      "-gamma \t\t The hyperparameter of the per-document sentiment proportion. The default is avgDocLength*0.05/numSentiLabs.\n",
      "-model_dir \t\t The directory of the previously trained model. (for inference only).\n",
      "-model \t\t The name of the previously trained model. (for inference only).\n"
     ]
    }
   ],
   "source": [
    "from reviews.config import data_dir, bin_dir, out_dir\n",
    "from reviews.models import JST\n",
    "\n",
    "alpha = 0.1\n",
    "beta = 0.001 # [0.001, 0.1, 0]\n",
    "gamma = 1 #[1, 1]\n",
    "n_topics = 20\n",
    "iterations = 1000\n",
    "\n",
    "model = JST(bin_dir, data_dir / \"jst\", out_dir / \"jst\")\n",
    "model.estimate(alpha, beta, gamma, n_topics, iterations)"
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 32-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "84ce2fb32a9c266b952fcf81060afaa66a94f1881626d999c4b836a5a7adb637"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
